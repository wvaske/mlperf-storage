model:
  name: dlrm

framework: pytorch

workflow:
  generate_data: False
  train: True
  checkpoint: False

dataset:
  data_folder: data/dlrm_parquet/
  format: parquet
  num_files_train: 65536
  num_samples_per_file: 1
  record_length_bytes: 512
  compression: snappy
  parquet:
    row_group_size: 100000
    read_mode: default
    columns:
      - name: dense_features
        dtype: float32
        size: 13
      - name: sparse_features
        dtype: float32
        size: 26
      - name: label
        dtype: float32
        size: 1

reader:
  data_loader: pytorch
  batch_size: 4096
  read_threads: 8
  file_shuffle: seed
  sample_shuffle: seed

train:
  epochs: 1
  computation_time: 0.007

metric:
  au: 0.70
