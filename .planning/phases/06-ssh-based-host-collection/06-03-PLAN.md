---
phase: 06-ssh-based-host-collection
plan: 03
type: execute
wave: 3
depends_on: ["06-02"]
files_modified:
  - mlpstorage/benchmarks/base.py
  - mlpstorage/rules/models.py
  - tests/unit/test_benchmark_base.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Benchmark base class supports SSH-based collection for non-MPI benchmarks"
    - "Collection happens at benchmark start and end (HOST-03)"
    - "Metadata includes both start and end cluster snapshots"
    - "Non-MPI benchmarks with --hosts use SSH collection automatically"
  artifacts:
    - path: "mlpstorage/benchmarks/base.py"
      provides: "SSH collection integration and start/end snapshots"
      contains: "_collect_cluster_start"
    - path: "mlpstorage/rules/models.py"
      provides: "ClusterSnapshots dataclass"
      contains: "class ClusterSnapshots"
    - path: "tests/unit/test_benchmark_base.py"
      provides: "Tests for collection method selection"
      contains: "test_selects_ssh_collection"
  key_links:
    - from: "mlpstorage/benchmarks/base.py"
      to: "SSHClusterCollector"
      via: "import and instantiation"
      pattern: "SSHClusterCollector\\("
    - from: "Benchmark.run"
      to: "_collect_cluster_start, _collect_cluster_end"
      via: "method calls"
      pattern: "_collect_cluster_start\\(|_collect_cluster_end\\("
---

<objective>
Integrate SSH-based collection into benchmark base class with start/end collection snapshots.

Purpose: Enable non-MPI benchmarks (KV Cache, VectorDB) to automatically use SSH collection and capture cluster state at both benchmark start and end (HOST-03 requirement).

Output: Updated base.py with collection method selection logic, ClusterSnapshots dataclass, and start/end collection integration.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-ssh-based-host-collection/06-RESEARCH.md
@.planning/phases/06-ssh-based-host-collection/06-01-SUMMARY.md
@.planning/phases/06-ssh-based-host-collection/06-02-SUMMARY.md

@mlpstorage/benchmarks/base.py
@mlpstorage/cluster_collector.py
@mlpstorage/rules/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add ClusterSnapshots dataclass to models.py</name>
  <files>mlpstorage/rules/models.py</files>
  <action>
Add a ClusterSnapshots dataclass to mlpstorage/rules/models.py after the HostInfo class (around line 285):

```python
@dataclass
class ClusterSnapshots:
    """Cluster information snapshots from benchmark start and end.

    Captures cluster state at two points during benchmark execution:
    - start: Collected immediately before benchmark execution begins
    - end: Collected immediately after benchmark execution completes

    This allows analysis of system state changes during the benchmark,
    such as memory pressure, I/O statistics delta, and load changes.

    Attributes:
        start: ClusterInformation collected at benchmark start
        end: ClusterInformation collected at benchmark end (may be None if not yet collected)
        collection_method: Method used for collection ('mpi', 'ssh', 'local')
    """
    start: 'ClusterInformation'
    end: Optional['ClusterInformation'] = None
    collection_method: str = 'unknown'

    def as_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for JSON serialization."""
        return {
            'start': self.start.as_dict() if self.start else None,
            'end': self.end.as_dict() if self.end else None,
            'collection_method': self.collection_method,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any], logger) -> Optional['ClusterSnapshots']:
        """Create ClusterSnapshots from a dictionary."""
        if data is None:
            return None

        start_data = data.get('start')
        end_data = data.get('end')

        start = ClusterInformation.from_dict(start_data, logger) if start_data else None
        end = ClusterInformation.from_dict(end_data, logger) if end_data else None

        if start is None:
            return None

        return cls(
            start=start,
            end=end,
            collection_method=data.get('collection_method', 'unknown')
        )
```

Also update the imports at the top of models.py to include Optional if not already present.
  </action>
  <verify>
python -c "from mlpstorage.rules.models import ClusterSnapshots; print('ClusterSnapshots imported successfully')"
  </verify>
  <done>ClusterSnapshots dataclass exists in models.py with start/end ClusterInformation fields and serialization methods.</done>
</task>

<task type="auto">
  <name>Task 2: Update Benchmark base class with SSH collection and snapshots</name>
  <files>mlpstorage/benchmarks/base.py</files>
  <action>
Update mlpstorage/benchmarks/base.py to add SSH-based collection support and start/end snapshots:

1. Add import for SSHClusterCollector:
```python
from mlpstorage.cluster_collector import collect_cluster_info, SSHClusterCollector
```

2. Add import for ClusterSnapshots:
```python
from mlpstorage.rules import BenchmarkVerifier, generate_output_location, ClusterInformation, ClusterSnapshots
```

3. Add new methods after _collect_cluster_information method:

```python
    def _should_use_ssh_collection(self) -> bool:
        """Determine if SSH-based collection should be used.

        SSH collection is used when:
        - hosts are specified
        - exec_type is NOT MPI (or exec_type is not set)
        - command is 'run' (not datagen/configview)

        Returns:
            True if SSH collection should be used, False otherwise.
        """
        if not hasattr(self.args, 'hosts') or not self.args.hosts:
            return False

        if hasattr(self.args, 'command') and self.args.command in ('datagen', 'configview'):
            return False

        if hasattr(self.args, 'skip_cluster_collection') and self.args.skip_cluster_collection:
            return False

        # Use SSH for non-MPI execution
        if not hasattr(self.args, 'exec_type') or self.args.exec_type != EXEC_TYPE.MPI:
            return True

        return False

    def _collect_via_ssh(self) -> Optional['ClusterInformation']:
        """Collect cluster information using SSH.

        Returns:
            ClusterInformation instance if collection succeeds, None otherwise.
        """
        try:
            self.logger.debug('Collecting cluster information via SSH...')

            ssh_username = getattr(self.args, 'ssh_username', None)
            timeout = getattr(self.args, 'cluster_collection_timeout', 60)

            collector = SSHClusterCollector(
                hosts=self.args.hosts,
                logger=self.logger,
                ssh_username=ssh_username,
                timeout_seconds=timeout
            )

            if not collector.is_available():
                self.logger.warning('SSH not available for cluster collection')
                return None

            result = collector.collect(self.args.hosts, timeout)

            if not result.success:
                self.logger.warning(f'SSH collection had errors: {result.errors}')

            # Create ClusterInformation from collected data
            cluster_info = ClusterInformation.from_mpi_collection(
                {**result.data, '_metadata': {
                    'collection_method': 'ssh',
                    'collection_timestamp': result.timestamp
                }},
                self.logger
            )

            self.logger.debug(
                f'Cluster info collected via SSH: '
                f'{cluster_info.num_hosts} hosts, '
                f'{cluster_info.total_memory_bytes / (1024**3):.1f} GB total memory'
            )

            return cluster_info

        except Exception as e:
            self.logger.warning(f'SSH cluster info collection failed: {e}')
            return None

    def _collect_cluster_start(self) -> None:
        """Collect cluster information at benchmark start.

        Stores the result in self._cluster_info_start for later use.
        Called at the beginning of run().
        """
        if not self._should_collect_cluster_info() and not self._should_use_ssh_collection():
            self.logger.debug('Skipping start cluster collection (conditions not met)')
            return

        if self._should_use_ssh_collection():
            self._cluster_info_start = self._collect_via_ssh()
            self._collection_method = 'ssh'
        else:
            self._cluster_info_start = self._collect_cluster_information()
            self._collection_method = 'mpi'

        if self._cluster_info_start:
            self.logger.debug(f'Collected start cluster info via {self._collection_method}')

    def _collect_cluster_end(self) -> None:
        """Collect cluster information at benchmark end.

        Only collects if start collection was performed.
        Creates ClusterSnapshots with both start and end data.
        """
        if not hasattr(self, '_cluster_info_start') or self._cluster_info_start is None:
            return

        if self._should_use_ssh_collection():
            self._cluster_info_end = self._collect_via_ssh()
        else:
            self._cluster_info_end = self._collect_cluster_information()

        if self._cluster_info_end:
            self.logger.debug(f'Collected end cluster info via {self._collection_method}')

        # Create ClusterSnapshots
        self.cluster_snapshots = ClusterSnapshots(
            start=self._cluster_info_start,
            end=self._cluster_info_end,
            collection_method=getattr(self, '_collection_method', 'unknown')
        )

        # Also set cluster_information to the start snapshot for backward compatibility
        self.cluster_information = self._cluster_info_start
```

4. Update the run() method to call start/end collection:

```python
    def run(self) -> int:
        """Execute the benchmark and track runtime.

        Wraps _run() with timing measurement and cluster collection.
        Updates self.runtime with the execution duration in seconds.

        Collects cluster information at start and end of benchmark
        (HOST-03 requirement).

        Returns:
            Exit code from _run().
        """
        self._validate_environment()

        # Collect cluster info at start (HOST-03)
        self._collect_cluster_start()

        start_time = time.time()
        result = self._run()
        self.runtime = time.time() - start_time

        # Collect cluster info at end (HOST-03)
        self._collect_cluster_end()

        return result
```

5. Update the metadata property to include cluster_snapshots:

In the metadata property, after the system_info section, add:

```python
        # Include cluster snapshots if available (start and end collection)
        if hasattr(self, 'cluster_snapshots') and self.cluster_snapshots:
            metadata['cluster_snapshots'] = self.cluster_snapshots.as_dict()
```
  </action>
  <verify>
python -c "from mlpstorage.benchmarks.base import Benchmark; print('Benchmark base imports successfully')"
  </verify>
  <done>Benchmark base class has SSH collection support, start/end collection methods, and updated run() method.</done>
</task>

<task type="auto">
  <name>Task 3: Add unit tests for collection method selection</name>
  <files>tests/unit/test_benchmark_base.py</files>
  <action>
Create tests/unit/test_benchmark_base.py to test the collection method selection logic:

```python
"""Unit tests for Benchmark base class collection functionality."""

import pytest
from argparse import Namespace
from unittest.mock import MagicMock, patch

from mlpstorage.config import EXEC_TYPE, BENCHMARK_TYPES


class TestBenchmarkCollectionSelection:
    """Tests for benchmark collection method selection."""

    @pytest.fixture
    def mock_logger(self):
        """Create a mock logger."""
        logger = MagicMock()
        logger.debug = MagicMock()
        logger.warning = MagicMock()
        logger.status = MagicMock()
        logger.verbose = MagicMock()
        logger.verboser = MagicMock()
        return logger

    def _create_benchmark_with_args(self, mock_logger, **kwargs):
        """Helper to create a benchmark with specific args."""
        # Import here to avoid circular imports during module loading
        from mlpstorage.benchmarks.base import Benchmark

        # Create a concrete subclass for testing
        class TestBenchmark(Benchmark):
            BENCHMARK_TYPE = BENCHMARK_TYPES.kv_cache

            def _run(self):
                return 0

        defaults = {
            'hosts': None,
            'exec_type': None,
            'command': 'run',
            'debug': False,
            'verbose': False,
            'stream_log_level': 'INFO',
            'results_dir': '/tmp/test_results',
            'what_if': True,  # Prevent actual execution
        }
        defaults.update(kwargs)
        args = Namespace(**defaults)

        with patch('mlpstorage.benchmarks.base.setup_logging', return_value=mock_logger):
            with patch('os.makedirs'):
                benchmark = TestBenchmark(args, logger=mock_logger, run_datetime='20260124_120000')

        return benchmark

    def test_should_use_ssh_collection_no_hosts(self, mock_logger):
        """Test that SSH collection is not used when no hosts specified."""
        benchmark = self._create_benchmark_with_args(mock_logger, hosts=None)
        assert benchmark._should_use_ssh_collection() is False

    def test_should_use_ssh_collection_empty_hosts(self, mock_logger):
        """Test that SSH collection is not used when hosts list is empty."""
        benchmark = self._create_benchmark_with_args(mock_logger, hosts=[])
        assert benchmark._should_use_ssh_collection() is False

    def test_should_use_ssh_collection_with_hosts_no_exec_type(self, mock_logger):
        """Test that SSH collection is used when hosts specified but no exec_type."""
        benchmark = self._create_benchmark_with_args(
            mock_logger,
            hosts=['node1', 'node2'],
            exec_type=None
        )
        assert benchmark._should_use_ssh_collection() is True

    def test_should_use_ssh_collection_non_mpi_exec_type(self, mock_logger):
        """Test that SSH collection is used for non-MPI exec_type."""
        benchmark = self._create_benchmark_with_args(
            mock_logger,
            hosts=['node1', 'node2'],
            exec_type=EXEC_TYPE.NONE
        )
        assert benchmark._should_use_ssh_collection() is True

    def test_should_not_use_ssh_collection_mpi_exec_type(self, mock_logger):
        """Test that SSH collection is not used when exec_type is MPI."""
        benchmark = self._create_benchmark_with_args(
            mock_logger,
            hosts=['node1', 'node2'],
            exec_type=EXEC_TYPE.MPI
        )
        assert benchmark._should_use_ssh_collection() is False

    def test_should_not_use_ssh_collection_for_datagen(self, mock_logger):
        """Test that SSH collection is skipped for datagen command."""
        benchmark = self._create_benchmark_with_args(
            mock_logger,
            hosts=['node1', 'node2'],
            command='datagen'
        )
        assert benchmark._should_use_ssh_collection() is False

    def test_should_not_use_ssh_collection_when_disabled(self, mock_logger):
        """Test that SSH collection is skipped when explicitly disabled."""
        benchmark = self._create_benchmark_with_args(
            mock_logger,
            hosts=['node1', 'node2'],
            skip_cluster_collection=True
        )
        assert benchmark._should_use_ssh_collection() is False

    def test_should_collect_cluster_info_no_hosts(self, mock_logger):
        """Test that MPI collection is not used when no hosts specified."""
        benchmark = self._create_benchmark_with_args(mock_logger, hosts=None)
        assert benchmark._should_collect_cluster_info() is False

    def test_should_collect_cluster_info_with_hosts_mpi(self, mock_logger):
        """Test that MPI collection is used with hosts and MPI exec_type."""
        benchmark = self._create_benchmark_with_args(
            mock_logger,
            hosts=['node1', 'node2'],
            exec_type=EXEC_TYPE.MPI
        )
        # _should_collect_cluster_info checks for hosts and command, exec_type
        # check is in _collect_cluster_information
        assert benchmark._should_collect_cluster_info() is True


class TestBenchmarkClusterSnapshots:
    """Tests for cluster snapshot functionality."""

    @pytest.fixture
    def mock_logger(self):
        """Create a mock logger."""
        logger = MagicMock()
        logger.debug = MagicMock()
        logger.warning = MagicMock()
        logger.status = MagicMock()
        logger.verbose = MagicMock()
        logger.verboser = MagicMock()
        return logger

    @patch('mlpstorage.benchmarks.base.SSHClusterCollector')
    def test_collect_cluster_start_uses_ssh(self, mock_ssh_collector_class, mock_logger):
        """Test that _collect_cluster_start uses SSH when appropriate."""
        from mlpstorage.benchmarks.base import Benchmark
        from mlpstorage.rules.models import ClusterInformation

        class TestBenchmark(Benchmark):
            BENCHMARK_TYPE = BENCHMARK_TYPES.kv_cache

            def _run(self):
                return 0

        # Setup mock collector
        mock_collector = MagicMock()
        mock_collector.is_available.return_value = True
        mock_result = MagicMock()
        mock_result.success = True
        mock_result.data = {'localhost': {'hostname': 'localhost', 'meminfo': {}}}
        mock_result.timestamp = '2026-01-24T12:00:00Z'
        mock_result.errors = []
        mock_collector.collect.return_value = mock_result
        mock_ssh_collector_class.return_value = mock_collector

        args = Namespace(
            hosts=['localhost'],
            exec_type=None,  # Non-MPI
            command='run',
            debug=False,
            verbose=False,
            stream_log_level='INFO',
            results_dir='/tmp/test_results',
            what_if=True,
            ssh_username=None,
            cluster_collection_timeout=60,
        )

        with patch('mlpstorage.benchmarks.base.setup_logging', return_value=mock_logger):
            with patch('os.makedirs'):
                with patch.object(ClusterInformation, 'from_mpi_collection') as mock_from_mpi:
                    mock_cluster_info = MagicMock()
                    mock_cluster_info.num_hosts = 1
                    mock_cluster_info.total_memory_bytes = 16 * 1024**3
                    mock_from_mpi.return_value = mock_cluster_info

                    benchmark = TestBenchmark(args, logger=mock_logger, run_datetime='20260124_120000')
                    benchmark._collect_cluster_start()

                    mock_ssh_collector_class.assert_called_once()
                    mock_collector.collect.assert_called_once()
                    assert hasattr(benchmark, '_cluster_info_start')
                    assert benchmark._collection_method == 'ssh'
```
  </action>
  <verify>pytest tests/unit/test_benchmark_base.py -v</verify>
  <done>Unit tests pass for collection method selection logic, verifying SSH collection is used for non-MPI benchmarks with hosts.</done>
</task>

</tasks>

<verification>
1. ClusterSnapshots dataclass exists: `python -c "from mlpstorage.rules.models import ClusterSnapshots"`
2. Benchmark base class imports successfully with new methods
3. Unit tests pass: `pytest tests/unit/test_benchmark_base.py -v`
4. SSH collection is selected for non-MPI benchmarks with hosts
5. run() calls start/end collection methods
</verification>

<success_criteria>
1. ClusterSnapshots dataclass holds start and end ClusterInformation
2. _should_use_ssh_collection returns True for non-MPI benchmarks with hosts
3. _collect_cluster_start and _collect_cluster_end called in run()
4. Metadata includes cluster_snapshots when collection occurs
5. SSH collection is used automatically for non-MPI benchmarks
6. All unit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/06-ssh-based-host-collection/06-03-SUMMARY.md`
</output>
