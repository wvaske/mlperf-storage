---
phase: 07-time-series-host-data-collection
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - mlpstorage/cluster_collector.py
  - tests/unit/test_cluster_collector.py
autonomous: true

must_haves:
  truths:
    - "MultiHostTimeSeriesCollector collects from multiple hosts in parallel"
    - "Localhost hosts use direct collection, remote hosts use SSH"
    - "Collection continues even if some hosts fail"
    - "Samples are organized by hostname"
  artifacts:
    - path: "mlpstorage/cluster_collector.py"
      provides: "MultiHostTimeSeriesCollector class"
      contains: "class MultiHostTimeSeriesCollector"
    - path: "tests/unit/test_cluster_collector.py"
      provides: "Unit tests for multi-host time-series collection"
      contains: "TestMultiHostTimeSeriesCollector"
  key_links:
    - from: "mlpstorage/cluster_collector.py MultiHostTimeSeriesCollector"
      to: "TimeSeriesCollector"
      via: "collection_loop pattern"
      pattern: "_stop_event\\.wait"
    - from: "mlpstorage/cluster_collector.py MultiHostTimeSeriesCollector"
      to: "ThreadPoolExecutor"
      via: "parallel host collection"
      pattern: "ThreadPoolExecutor"
    - from: "mlpstorage/cluster_collector.py MultiHostTimeSeriesCollector"
      to: "_is_localhost"
      via: "localhost detection for local collection"
      pattern: "_is_localhost"
    - from: "mlpstorage/cluster_collector.py MultiHostTimeSeriesCollector"
      to: "concurrent.futures.as_completed"
      via: "future completion handling"
      pattern: "from concurrent\\.futures import.*as_completed"
---

<objective>
Extend time-series collection to support multiple hosts via SSH.

Purpose: Enables HOST-05 (parallel collection process without benchmark performance impact) by collecting time-series data from all benchmark hosts simultaneously using SSH for remote hosts and direct collection for localhost.

Output:
- MultiHostTimeSeriesCollector class that collects from multiple hosts in parallel
- SSH-based remote collection using existing SSHClusterCollector patterns
- Localhost optimization (direct collection without SSH)
- Unit tests for multi-host collection
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-time-series-host-data-collection/07-RESEARCH.md
@.planning/phases/07-time-series-host-data-collection/07-01-SUMMARY.md

# Key existing patterns
@mlpstorage/cluster_collector.py
@tests/unit/test_cluster_collector.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add MultiHostTimeSeriesCollector class</name>
  <files>mlpstorage/cluster_collector.py</files>
  <action>
Add the MultiHostTimeSeriesCollector class after the TimeSeriesCollector class. This class extends the time-series collection pattern to support multiple hosts with parallel SSH collection.

1. Add import at top of file (with existing concurrent.futures imports, or add if not present):
```python
from concurrent.futures import ThreadPoolExecutor, as_completed
```

Note: The `as_completed` import is REQUIRED for the `_collect_all_hosts` method. Ensure both ThreadPoolExecutor and as_completed are imported from concurrent.futures.

2. Add the TIMESERIES_SSH_SCRIPT and MultiHostTimeSeriesCollector class:

```python
# Lightweight SSH script for time-series collection (collects only dynamic metrics)
TIMESERIES_SSH_SCRIPT = '''
import json
import socket
import time

def collect():
    result = {"timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()), "hostname": socket.gethostname(), "errors": {}}

    files = [
        ("/proc/diskstats", "diskstats"),
        ("/proc/vmstat", "vmstat"),
        ("/proc/loadavg", "loadavg"),
        ("/proc/meminfo", "meminfo"),
        ("/proc/net/dev", "netdev"),
    ]

    for path, key in files:
        try:
            with open(path) as f:
                result[key] = f.read()
        except Exception as e:
            result["errors"][key] = str(e)
            result[key] = ""

    if not result["errors"]:
        del result["errors"]
    print(json.dumps(result))

collect()
'''


class MultiHostTimeSeriesCollector:
    """Collects time-series metrics from multiple hosts in parallel.

    Uses SSH for remote hosts and direct collection for localhost.
    Collection happens in a background thread with parallel SSH calls
    at each interval using ThreadPoolExecutor.

    Usage:
        collector = MultiHostTimeSeriesCollector(
            hosts=['host1', 'host2', 'localhost'],
            interval_seconds=10.0
        )
        collector.start()
        # ... run benchmark ...
        samples_by_host = collector.stop()

    Attributes:
        hosts: List of hostnames to collect from.
        interval_seconds: Time between collection rounds.
        max_samples: Maximum samples per host to keep.
    """

    def __init__(
        self,
        hosts: List[str],
        interval_seconds: float = 10.0,
        max_samples: int = 3600,
        ssh_username: Optional[str] = None,
        ssh_timeout: int = 30,
        max_workers: int = 10,
        logger=None
    ):
        """Initialize multi-host time-series collector.

        Args:
            hosts: List of hostnames/IPs to collect from.
            interval_seconds: Time between samples (default: 10 seconds).
            max_samples: Maximum samples per host (default: 3600).
            ssh_username: Optional SSH username for remote hosts.
            ssh_timeout: SSH connection timeout in seconds.
            max_workers: Maximum parallel SSH connections.
            logger: Optional logger instance.
        """
        self.hosts = self._get_unique_hosts(hosts)
        self.interval_seconds = interval_seconds
        self.max_samples = max_samples
        self.ssh_username = ssh_username
        self.ssh_timeout = ssh_timeout
        self.max_workers = max_workers
        self.logger = logger

        self._stop_event = threading.Event()
        self._samples_by_host: Dict[str, List[Dict[str, Any]]] = {h: [] for h in self.hosts}
        self._start_time: Optional[str] = None
        self._end_time: Optional[str] = None
        self._thread = threading.Thread(
            target=self._collection_loop,
            daemon=False,
            name="MultiHostTimeSeriesCollector"
        )
        self._started = False
        self._stopped = False

    def _get_unique_hosts(self, hosts: List[str]) -> List[str]:
        """Extract unique hostnames from hosts list (removing slot counts)."""
        unique = []
        seen = set()
        for host in hosts:
            hostname = host.split(':')[0].strip() if ':' in host else host.strip()
            if hostname and hostname not in seen:
                seen.add(hostname)
                unique.append(hostname)
        return unique

    def _build_ssh_command(self, hostname: str, remote_cmd: str) -> List[str]:
        """Build SSH command for remote collection."""
        cmd = [
            'ssh',
            '-o', 'BatchMode=yes',
            '-o', f'ConnectTimeout={self.ssh_timeout}',
            '-o', 'StrictHostKeyChecking=accept-new',
        ]
        if self.ssh_username:
            cmd.extend(['-l', self.ssh_username])
        cmd.extend([hostname, remote_cmd])
        return cmd

    def _parse_remote_sample(self, raw_data: Dict[str, Any]) -> Dict[str, Any]:
        """Parse raw /proc file contents from SSH collection into structured data."""
        sample = {
            'timestamp': raw_data.get('timestamp', time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime())),
            'hostname': raw_data.get('hostname', 'unknown'),
            'errors': raw_data.get('errors', {}),
        }

        # Parse diskstats
        if raw_data.get('diskstats'):
            disks = parse_proc_diskstats(raw_data['diskstats'])
            sample['diskstats'] = [d.to_dict() for d in disks]

        # Parse vmstat
        if raw_data.get('vmstat'):
            sample['vmstat'] = parse_proc_vmstat(raw_data['vmstat'])

        # Parse loadavg
        if raw_data.get('loadavg'):
            load_1, load_5, load_15, running, total = parse_proc_loadavg(raw_data['loadavg'])
            sample['loadavg'] = {
                'load_1min': load_1,
                'load_5min': load_5,
                'load_15min': load_15,
                'running_processes': running,
                'total_processes': total,
            }

        # Parse meminfo
        if raw_data.get('meminfo'):
            sample['meminfo'] = parse_proc_meminfo(raw_data['meminfo'])

        # Parse netdev
        if raw_data.get('netdev'):
            interfaces = parse_proc_net_dev(raw_data['netdev'])
            sample['netdev'] = [n.to_dict() for n in interfaces]

        if not sample['errors']:
            del sample['errors']

        return sample

    def _collect_from_host(self, hostname: str) -> Dict[str, Any]:
        """Collect single sample from a host (local or remote)."""
        if _is_localhost(hostname):
            return collect_timeseries_sample()

        # Remote collection via SSH
        remote_cmd = f"python3 -c '{TIMESERIES_SSH_SCRIPT}'"
        cmd = self._build_ssh_command(hostname, remote_cmd)

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.ssh_timeout + 10
            )

            if result.returncode != 0:
                error_msg = result.stderr.strip() or f'SSH failed with code {result.returncode}'
                return {
                    'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
                    'hostname': hostname,
                    'errors': {'ssh': error_msg}
                }

            raw_data = json.loads(result.stdout)
            return self._parse_remote_sample(raw_data)

        except subprocess.TimeoutExpired:
            return {
                'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
                'hostname': hostname,
                'errors': {'ssh': f'Timeout after {self.ssh_timeout}s'}
            }
        except json.JSONDecodeError as e:
            return {
                'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
                'hostname': hostname,
                'errors': {'json': str(e)}
            }
        except Exception as e:
            return {
                'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
                'hostname': hostname,
                'errors': {'collection': str(e)}
            }

    def _collect_all_hosts(self) -> None:
        """Collect from all hosts in parallel."""
        with ThreadPoolExecutor(max_workers=min(self.max_workers, len(self.hosts))) as executor:
            futures = {
                executor.submit(self._collect_from_host, host): host
                for host in self.hosts
            }

            for future in as_completed(futures, timeout=self.interval_seconds):
                host = futures[future]
                try:
                    sample = future.result(timeout=self.interval_seconds / 2)

                    # Enforce max_samples per host
                    if len(self._samples_by_host[host]) < self.max_samples:
                        self._samples_by_host[host].append(sample)

                except Exception as e:
                    # Log but continue - don't fail collection for one host
                    if self.logger:
                        self.logger.debug(f'Time-series collection from {host} failed: {e}')
                    # Add error sample
                    if len(self._samples_by_host[host]) < self.max_samples:
                        self._samples_by_host[host].append({
                            'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
                            'hostname': host,
                            'errors': {'collection': str(e)}
                        })

    def _collection_loop(self) -> None:
        """Run periodic collection until stop signal."""
        while not self._stop_event.is_set():
            try:
                self._collect_all_hosts()
            except Exception as e:
                if self.logger:
                    self.logger.debug(f'MultiHostTimeSeriesCollector collection error: {e}')

            self._stop_event.wait(timeout=self.interval_seconds)

    def start(self) -> None:
        """Start background collection.

        Raises:
            RuntimeError: If collector already started or stopped.
        """
        if self._started:
            raise RuntimeError('MultiHostTimeSeriesCollector already started')
        if self._stopped:
            raise RuntimeError('MultiHostTimeSeriesCollector already stopped; create new instance')

        self._start_time = time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime())
        self._started = True
        self._thread.start()

        if self.logger:
            self.logger.debug(
                f'MultiHostTimeSeriesCollector started ({len(self.hosts)} hosts, '
                f'interval={self.interval_seconds}s)'
            )

    def stop(self) -> Dict[str, List[Dict[str, Any]]]:
        """Stop collection and return samples organized by host.

        Returns:
            Dictionary mapping hostname -> list of samples.

        Raises:
            RuntimeError: If collector not started.
        """
        if not self._started:
            raise RuntimeError('MultiHostTimeSeriesCollector not started')
        if self._stopped:
            return self._samples_by_host

        self._stop_event.set()
        self._thread.join(timeout=self.interval_seconds + 10)

        self._end_time = time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime())
        self._stopped = True

        total_samples = sum(len(samples) for samples in self._samples_by_host.values())
        if self.logger:
            self.logger.debug(
                f'MultiHostTimeSeriesCollector stopped ({total_samples} total samples '
                f'from {len(self.hosts)} hosts)'
            )

        return self._samples_by_host

    @property
    def samples_by_host(self) -> Dict[str, List[Dict[str, Any]]]:
        """Get collected samples organized by host."""
        return self._samples_by_host

    @property
    def start_time(self) -> Optional[str]:
        """Get collection start time (ISO format)."""
        return self._start_time

    @property
    def end_time(self) -> Optional[str]:
        """Get collection end time (ISO format)."""
        return self._end_time

    @property
    def is_running(self) -> bool:
        """Check if collector is currently running."""
        return self._started and not self._stopped

    def get_hosts_with_data(self) -> List[str]:
        """Get list of hosts that have at least one sample."""
        return [host for host, samples in self._samples_by_host.items() if samples]
```
  </action>
  <verify>Run `python -c "from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector; print('OK')"` - should print OK</verify>
  <done>MultiHostTimeSeriesCollector class exists with start()/stop() methods and parallel SSH collection</done>
</task>

<task type="auto">
  <name>Task 2: Add unit tests for MultiHostTimeSeriesCollector</name>
  <files>tests/unit/test_cluster_collector.py</files>
  <action>
Add unit tests for MultiHostTimeSeriesCollector at the end of the test file.

```python
class TestMultiHostTimeSeriesCollector:
    """Tests for MultiHostTimeSeriesCollector class."""

    def test_init_sets_defaults(self):
        """Collector should initialize with default values."""
        from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector

        collector = MultiHostTimeSeriesCollector(hosts=['localhost'])

        assert collector.interval_seconds == 10.0
        assert collector.max_samples == 3600
        assert 'localhost' in collector.hosts
        assert not collector.is_running

    def test_init_custom_values(self):
        """Collector should accept custom parameters."""
        from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector

        collector = MultiHostTimeSeriesCollector(
            hosts=['host1', 'host2'],
            interval_seconds=5.0,
            max_samples=100,
            ssh_timeout=15
        )

        assert collector.interval_seconds == 5.0
        assert collector.max_samples == 100
        assert len(collector.hosts) == 2

    def test_deduplicates_hosts(self):
        """Collector should remove duplicate hosts."""
        from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector

        collector = MultiHostTimeSeriesCollector(
            hosts=['host1', 'host1', 'host2', 'host2:2']
        )

        assert len(collector.hosts) == 2
        assert 'host1' in collector.hosts
        assert 'host2' in collector.hosts

    def test_removes_slot_counts(self):
        """Collector should strip slot counts from hosts."""
        from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector

        collector = MultiHostTimeSeriesCollector(
            hosts=['host1:4', 'host2:8']
        )

        assert 'host1' in collector.hosts
        assert 'host2' in collector.hosts
        assert 'host1:4' not in collector.hosts

    def test_start_sets_running(self):
        """start() should set is_running to True."""
        from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector

        collector = MultiHostTimeSeriesCollector(
            hosts=['localhost'],
            interval_seconds=0.1
        )

        try:
            collector.start()
            assert collector.is_running
            assert collector.start_time is not None
        finally:
            collector.stop()

    def test_stop_returns_samples_by_host(self):
        """stop() should return dict organized by host."""
        from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector

        collector = MultiHostTimeSeriesCollector(
            hosts=['localhost'],
            interval_seconds=0.1
        )

        collector.start()
        time.sleep(0.25)
        samples_by_host = collector.stop()

        assert isinstance(samples_by_host, dict)
        assert not collector.is_running
        assert collector.end_time is not None

    def test_collects_from_localhost(self):
        """Should collect samples from localhost."""
        from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector

        collector = MultiHostTimeSeriesCollector(
            hosts=['localhost'],
            interval_seconds=0.1
        )

        collector.start()
        time.sleep(0.25)
        samples_by_host = collector.stop()

        # Should have localhost data
        assert 'localhost' in samples_by_host
        assert len(samples_by_host['localhost']) >= 1

    def test_samples_have_expected_structure(self):
        """Collected samples should have timestamp and hostname."""
        from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector

        collector = MultiHostTimeSeriesCollector(
            hosts=['localhost'],
            interval_seconds=0.1
        )

        collector.start()
        time.sleep(0.15)
        samples_by_host = collector.stop()

        if samples_by_host.get('localhost'):
            sample = samples_by_host['localhost'][0]
            assert 'timestamp' in sample
            assert 'hostname' in sample

    def test_max_samples_per_host_enforced(self):
        """Should not exceed max_samples per host."""
        from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector

        collector = MultiHostTimeSeriesCollector(
            hosts=['localhost'],
            interval_seconds=0.05,
            max_samples=3
        )

        collector.start()
        time.sleep(0.3)  # Would collect ~6 without limit
        samples_by_host = collector.stop()

        assert len(samples_by_host.get('localhost', [])) <= 3

    def test_start_twice_raises_error(self):
        """Starting twice should raise RuntimeError."""
        from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector

        collector = MultiHostTimeSeriesCollector(
            hosts=['localhost'],
            interval_seconds=0.1
        )

        try:
            collector.start()
            with pytest.raises(RuntimeError, match="already started"):
                collector.start()
        finally:
            collector.stop()

    def test_stop_without_start_raises_error(self):
        """Stopping without starting should raise RuntimeError."""
        from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector

        collector = MultiHostTimeSeriesCollector(hosts=['localhost'])

        with pytest.raises(RuntimeError, match="not started"):
            collector.stop()

    def test_get_hosts_with_data(self):
        """get_hosts_with_data should return hosts that have samples."""
        from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector

        collector = MultiHostTimeSeriesCollector(
            hosts=['localhost'],
            interval_seconds=0.1
        )

        collector.start()
        time.sleep(0.15)
        collector.stop()

        hosts_with_data = collector.get_hosts_with_data()
        assert 'localhost' in hosts_with_data

    def test_handles_unreachable_host_gracefully(self):
        """Should continue collecting even if one host fails."""
        from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector

        collector = MultiHostTimeSeriesCollector(
            hosts=['localhost', 'nonexistent-host-12345.invalid'],
            interval_seconds=0.2,
            ssh_timeout=1  # Short timeout for test
        )

        collector.start()
        time.sleep(0.5)
        samples_by_host = collector.stop()

        # localhost should still have data
        assert len(samples_by_host.get('localhost', [])) >= 1

        # Unreachable host should have error samples
        bad_host_samples = samples_by_host.get('nonexistent-host-12345.invalid', [])
        if bad_host_samples:
            # If we got samples, they should have errors
            assert any('errors' in s for s in bad_host_samples)
```

Add import at top of test file:
```python
from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector
```
  </action>
  <verify>Run `pytest tests/unit/test_cluster_collector.py -v -k "MultiHost" --tb=short` - all tests should pass</verify>
  <done>All MultiHostTimeSeriesCollector unit tests pass</done>
</task>

</tasks>

<verification>
1. Import check (including as_completed): `python -c "from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector, TIMESERIES_SSH_SCRIPT; from concurrent.futures import as_completed; print('OK')"`
2. Functional test: `python -c "from mlpstorage.cluster_collector import MultiHostTimeSeriesCollector; import time; c = MultiHostTimeSeriesCollector(hosts=['localhost'], interval_seconds=0.5); c.start(); time.sleep(1.5); s = c.stop(); print(f'Collected {len(s[\"localhost\"])} samples from localhost')"`
3. Unit tests: `pytest tests/unit/test_cluster_collector.py -v -k "MultiHost" --tb=short`
</verification>

<success_criteria>
1. MultiHostTimeSeriesCollector class exists with start()/stop() methods
2. Collector uses ThreadPoolExecutor for parallel host collection
3. as_completed is imported from concurrent.futures for future handling
4. Localhost hosts use direct collection (no SSH)
5. Remote hosts use SSH with TIMESERIES_SSH_SCRIPT
6. Collection continues even when some hosts fail
7. Samples are organized by hostname in stop() return value
8. All unit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/07-time-series-host-data-collection/07-02-SUMMARY.md`
</output>
