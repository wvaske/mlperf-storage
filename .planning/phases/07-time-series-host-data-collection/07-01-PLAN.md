---
phase: 07-time-series-host-data-collection
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - mlpstorage/rules/models.py
  - mlpstorage/cluster_collector.py
  - tests/unit/test_cluster_collector.py
autonomous: true

must_haves:
  truths:
    - "TimeSeriesSample dataclass can be instantiated with all dynamic metric fields"
    - "TimeSeriesData dataclass aggregates samples by host with metadata"
    - "collect_timeseries_sample() returns a dict with diskstats, vmstat, loadavg, meminfo, netdev"
    - "TimeSeriesCollector collects samples at specified intervals in background thread"
    - "TimeSeriesCollector.stop() returns all collected samples"
  artifacts:
    - path: "mlpstorage/rules/models.py"
      provides: "TimeSeriesSample and TimeSeriesData dataclasses"
      contains: "class TimeSeriesSample"
    - path: "mlpstorage/cluster_collector.py"
      provides: "collect_timeseries_sample function and TimeSeriesCollector class"
      contains: "class TimeSeriesCollector"
    - path: "tests/unit/test_cluster_collector.py"
      provides: "Unit tests for time-series collection"
      contains: "test_timeseries"
  key_links:
    - from: "mlpstorage/cluster_collector.py"
      to: "parse_proc_diskstats, parse_proc_vmstat, parse_proc_loadavg, parse_proc_meminfo, parse_proc_net_dev"
      via: "function calls in collect_timeseries_sample"
      pattern: "parse_proc_"
    - from: "mlpstorage/cluster_collector.py"
      to: "threading.Event"
      via: "stop signal mechanism"
      pattern: "threading\\.Event"
---

<objective>
Implement core time-series data collection infrastructure including dataclasses and single-host collector.

Purpose: Provides the foundation for HOST-04 (time-series collection at 10 sec intervals). This plan creates the dataclasses for samples/data and the core TimeSeriesCollector class with background thread.

Output:
- TimeSeriesSample and TimeSeriesData dataclasses in models.py
- collect_timeseries_sample() function that collects dynamic /proc metrics
- TimeSeriesCollector class with start()/stop() methods
- Unit tests for all new functionality
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-time-series-host-data-collection/07-RESEARCH.md

# Key existing files to understand patterns
@mlpstorage/cluster_collector.py
@mlpstorage/rules/models.py
@tests/unit/test_cluster_collector.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add TimeSeriesSample and TimeSeriesData dataclasses</name>
  <files>mlpstorage/rules/models.py</files>
  <action>
Add two new dataclasses to models.py following the existing ClusterSnapshots pattern:

1. TimeSeriesSample dataclass (after ClusterSnapshots):
```python
@dataclass
class TimeSeriesSample:
    """Single time-series sample from one host.

    Contains dynamic metrics that change over time during benchmark execution.
    Static information (cpuinfo, os_release) is excluded as it doesn't change.
    """
    timestamp: str  # ISO format YYYY-MM-DDTHH:MM:SSZ
    hostname: str
    diskstats: Optional[List[Dict[str, Any]]] = None  # List of disk stat dicts
    vmstat: Optional[Dict[str, int]] = None  # vmstat key-value pairs
    meminfo: Optional[Dict[str, int]] = None  # meminfo key-value pairs
    loadavg: Optional[Dict[str, float]] = None  # load average data
    netdev: Optional[List[Dict[str, Any]]] = None  # network interface stats
    errors: Optional[Dict[str, str]] = None  # any collection errors

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary, excluding None values."""
        return {k: v for k, v in asdict(self).items() if v is not None}

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'TimeSeriesSample':
        """Create instance from dictionary."""
        return cls(**{k: v for k, v in data.items() if k in cls.__dataclass_fields__})
```

2. TimeSeriesData dataclass (after TimeSeriesSample):
```python
@dataclass
class TimeSeriesData:
    """Complete time-series collection for a benchmark run.

    Aggregates all samples collected during benchmark execution,
    organized by host with collection metadata.
    """
    collection_interval_seconds: float
    start_time: str  # ISO format
    end_time: str  # ISO format (set when collection stops)
    num_samples: int
    samples_by_host: Dict[str, List[TimeSeriesSample]]
    collection_method: str  # 'local', 'ssh'
    hosts_requested: List[str]
    hosts_collected: List[str]

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for JSON serialization."""
        return {
            'collection_interval_seconds': self.collection_interval_seconds,
            'start_time': self.start_time,
            'end_time': self.end_time,
            'num_samples': self.num_samples,
            'samples_by_host': {
                host: [s.to_dict() for s in samples]
                for host, samples in self.samples_by_host.items()
            },
            'collection_method': self.collection_method,
            'hosts_requested': self.hosts_requested,
            'hosts_collected': self.hosts_collected,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'TimeSeriesData':
        """Create instance from dictionary."""
        samples_by_host = {}
        for host, samples in data.get('samples_by_host', {}).items():
            samples_by_host[host] = [TimeSeriesSample.from_dict(s) for s in samples]

        return cls(
            collection_interval_seconds=data.get('collection_interval_seconds', 10.0),
            start_time=data.get('start_time', ''),
            end_time=data.get('end_time', ''),
            num_samples=data.get('num_samples', 0),
            samples_by_host=samples_by_host,
            collection_method=data.get('collection_method', 'unknown'),
            hosts_requested=data.get('hosts_requested', []),
            hosts_collected=data.get('hosts_collected', []),
        )
```

Add required import at top if not already present: `from dataclasses import dataclass, field, asdict`
  </action>
  <verify>Run `python -c "from mlpstorage.rules.models import TimeSeriesSample, TimeSeriesData; print('OK')"` - should print OK</verify>
  <done>TimeSeriesSample and TimeSeriesData dataclasses exist with to_dict() and from_dict() methods</done>
</task>

<task type="auto">
  <name>Task 2: Add collect_timeseries_sample() and TimeSeriesCollector</name>
  <files>mlpstorage/cluster_collector.py</files>
  <action>
Add time-series collection functionality to cluster_collector.py. Place new code after the SSHClusterCollector class.

1. Add import at top of file:
```python
import threading
```

2. Add collect_timeseries_sample() function:
```python
# =============================================================================
# Time-Series Collection
# =============================================================================

def collect_timeseries_sample() -> Dict[str, Any]:
    """Collect time-varying system metrics for time-series analysis.

    Collects only dynamic metrics that change during benchmark execution:
    - diskstats: I/O statistics per device
    - vmstat: Virtual memory statistics
    - loadavg: System load averages
    - meminfo: Memory usage
    - netdev: Network interface statistics

    Static information (cpuinfo, os_release) is excluded as it doesn't
    change between samples.

    Returns:
        Dictionary containing timestamp, hostname, and metric data.
        Individual metric keys may be missing if collection fails.
    """
    sample = {
        'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
        'hostname': socket.gethostname(),
        'errors': {},
    }

    # Collect /proc/diskstats
    try:
        with open('/proc/diskstats', 'r') as f:
            disks = parse_proc_diskstats(f.read())
            sample['diskstats'] = [d.to_dict() for d in disks]
    except Exception as e:
        sample['errors']['diskstats'] = str(e)

    # Collect /proc/vmstat
    try:
        with open('/proc/vmstat', 'r') as f:
            sample['vmstat'] = parse_proc_vmstat(f.read())
    except Exception as e:
        sample['errors']['vmstat'] = str(e)

    # Collect /proc/loadavg
    try:
        with open('/proc/loadavg', 'r') as f:
            load_1, load_5, load_15, running, total = parse_proc_loadavg(f.read())
            sample['loadavg'] = {
                'load_1min': load_1,
                'load_5min': load_5,
                'load_15min': load_15,
                'running_processes': running,
                'total_processes': total,
            }
    except Exception as e:
        sample['errors']['loadavg'] = str(e)

    # Collect /proc/meminfo
    try:
        with open('/proc/meminfo', 'r') as f:
            sample['meminfo'] = parse_proc_meminfo(f.read())
    except Exception as e:
        sample['errors']['meminfo'] = str(e)

    # Collect /proc/net/dev
    try:
        with open('/proc/net/dev', 'r') as f:
            interfaces = parse_proc_net_dev(f.read())
            sample['netdev'] = [n.to_dict() for n in interfaces]
    except Exception as e:
        sample['errors']['netdev'] = str(e)

    # Remove errors dict if empty
    if not sample['errors']:
        del sample['errors']

    return sample
```

3. Add TimeSeriesCollector class:
```python
class TimeSeriesCollector:
    """Collects time-series system metrics in a background thread.

    Uses a non-daemon thread with Event signaling for graceful shutdown.
    Samples are collected at regular intervals and stored in memory.

    Usage:
        collector = TimeSeriesCollector(interval_seconds=10.0)
        collector.start()
        # ... run benchmark ...
        samples = collector.stop()

    Attributes:
        interval_seconds: Time between samples in seconds.
        max_samples: Maximum number of samples to keep (prevents memory issues).
    """

    def __init__(
        self,
        interval_seconds: float = 10.0,
        max_samples: int = 3600,
        logger=None
    ):
        """Initialize the time-series collector.

        Args:
            interval_seconds: Time between samples (default: 10 seconds).
            max_samples: Maximum samples to keep (default: 3600 = 10 hours at 10s).
            logger: Optional logger instance for debug output.
        """
        self.interval_seconds = interval_seconds
        self.max_samples = max_samples
        self.logger = logger

        self._stop_event = threading.Event()
        self._samples: List[Dict[str, Any]] = []
        self._start_time: Optional[str] = None
        self._end_time: Optional[str] = None
        self._thread = threading.Thread(
            target=self._collection_loop,
            daemon=False,  # Non-daemon for graceful shutdown
            name="TimeSeriesCollector"
        )
        self._started = False
        self._stopped = False

    def _collection_loop(self):
        """Run periodic collection until stop signal."""
        while not self._stop_event.is_set():
            try:
                sample = collect_timeseries_sample()

                # Enforce max_samples limit
                if len(self._samples) < self.max_samples:
                    self._samples.append(sample)
                elif self.logger:
                    # Only log once when we hit the limit
                    if len(self._samples) == self.max_samples:
                        self.logger.warning(
                            f'TimeSeriesCollector reached max_samples limit ({self.max_samples}). '
                            f'Further samples will be dropped.'
                        )

            except Exception as e:
                if self.logger:
                    self.logger.debug(f'TimeSeriesCollector sample error: {e}')

            # Use wait(timeout) instead of sleep() for quick response to stop signal
            self._stop_event.wait(timeout=self.interval_seconds)

    def start(self) -> None:
        """Start background collection.

        Raises:
            RuntimeError: If collector was already started or stopped.
        """
        if self._started:
            raise RuntimeError('TimeSeriesCollector already started')
        if self._stopped:
            raise RuntimeError('TimeSeriesCollector already stopped; create a new instance')

        self._start_time = time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime())
        self._started = True
        self._thread.start()

        if self.logger:
            self.logger.debug(
                f'TimeSeriesCollector started (interval={self.interval_seconds}s, '
                f'max_samples={self.max_samples})'
            )

    def stop(self) -> List[Dict[str, Any]]:
        """Stop collection and return all samples.

        Returns:
            List of sample dictionaries collected during the run.

        Raises:
            RuntimeError: If collector was not started.
        """
        if not self._started:
            raise RuntimeError('TimeSeriesCollector not started')
        if self._stopped:
            return self._samples

        self._stop_event.set()
        # Wait for thread with timeout slightly longer than interval
        self._thread.join(timeout=self.interval_seconds + 5)

        self._end_time = time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime())
        self._stopped = True

        if self.logger:
            self.logger.debug(
                f'TimeSeriesCollector stopped ({len(self._samples)} samples collected)'
            )

        return self._samples

    @property
    def samples(self) -> List[Dict[str, Any]]:
        """Get collected samples (may be incomplete if still running)."""
        return self._samples

    @property
    def start_time(self) -> Optional[str]:
        """Get collection start time (ISO format)."""
        return self._start_time

    @property
    def end_time(self) -> Optional[str]:
        """Get collection end time (ISO format)."""
        return self._end_time

    @property
    def is_running(self) -> bool:
        """Check if collector is currently running."""
        return self._started and not self._stopped
```
  </action>
  <verify>Run `python -c "from mlpstorage.cluster_collector import collect_timeseries_sample, TimeSeriesCollector; print('OK')"` - should print OK</verify>
  <done>collect_timeseries_sample() function and TimeSeriesCollector class exist with start()/stop() methods</done>
</task>

<task type="auto">
  <name>Task 3: Add unit tests for time-series collection</name>
  <files>tests/unit/test_cluster_collector.py</files>
  <action>
Add comprehensive unit tests for the new time-series collection functionality. Add tests at the end of the existing test file.

```python
# =============================================================================
# Time-Series Collection Tests
# =============================================================================

class TestCollectTimeseriesSample:
    """Tests for collect_timeseries_sample function."""

    def test_returns_dict_with_required_fields(self):
        """Sample should contain timestamp and hostname."""
        sample = collect_timeseries_sample()

        assert isinstance(sample, dict)
        assert 'timestamp' in sample
        assert 'hostname' in sample
        # Timestamp should be ISO format
        assert 'T' in sample['timestamp']
        assert sample['timestamp'].endswith('Z')

    def test_contains_diskstats(self):
        """Sample should contain diskstats if available."""
        sample = collect_timeseries_sample()

        # On Linux, diskstats should be present
        if 'diskstats' in sample:
            assert isinstance(sample['diskstats'], list)
            if sample['diskstats']:
                # Each disk should have device_name
                assert 'device_name' in sample['diskstats'][0]

    def test_contains_vmstat(self):
        """Sample should contain vmstat if available."""
        sample = collect_timeseries_sample()

        if 'vmstat' in sample:
            assert isinstance(sample['vmstat'], dict)

    def test_contains_loadavg(self):
        """Sample should contain loadavg if available."""
        sample = collect_timeseries_sample()

        if 'loadavg' in sample:
            assert isinstance(sample['loadavg'], dict)
            assert 'load_1min' in sample['loadavg']
            assert 'load_5min' in sample['loadavg']
            assert 'load_15min' in sample['loadavg']

    def test_contains_meminfo(self):
        """Sample should contain meminfo if available."""
        sample = collect_timeseries_sample()

        if 'meminfo' in sample:
            assert isinstance(sample['meminfo'], dict)

    def test_contains_netdev(self):
        """Sample should contain netdev if available."""
        sample = collect_timeseries_sample()

        if 'netdev' in sample:
            assert isinstance(sample['netdev'], list)

    def test_no_errors_key_when_successful(self):
        """Sample should not have errors key if all collections succeed."""
        sample = collect_timeseries_sample()

        # On a normal Linux system, there should be no errors
        # (but we don't assert this as the test env may vary)
        if 'errors' in sample:
            # If errors present, it should be a dict
            assert isinstance(sample['errors'], dict)


class TestTimeSeriesCollector:
    """Tests for TimeSeriesCollector class."""

    def test_init_sets_defaults(self):
        """Collector should initialize with default values."""
        collector = TimeSeriesCollector()

        assert collector.interval_seconds == 10.0
        assert collector.max_samples == 3600
        assert collector.samples == []
        assert collector.start_time is None
        assert collector.end_time is None
        assert not collector.is_running

    def test_init_custom_values(self):
        """Collector should accept custom interval and max_samples."""
        collector = TimeSeriesCollector(interval_seconds=5.0, max_samples=100)

        assert collector.interval_seconds == 5.0
        assert collector.max_samples == 100

    def test_start_sets_running(self):
        """start() should set is_running to True."""
        collector = TimeSeriesCollector(interval_seconds=0.1)

        try:
            collector.start()
            assert collector.is_running
            assert collector.start_time is not None
        finally:
            collector.stop()

    def test_stop_returns_samples(self):
        """stop() should return collected samples."""
        collector = TimeSeriesCollector(interval_seconds=0.1)

        collector.start()
        time.sleep(0.25)  # Allow a couple samples
        samples = collector.stop()

        assert isinstance(samples, list)
        assert not collector.is_running
        assert collector.end_time is not None

    def test_collects_samples_at_interval(self):
        """Collector should gather samples at specified interval."""
        collector = TimeSeriesCollector(interval_seconds=0.1)

        collector.start()
        time.sleep(0.35)  # Should get 3-4 samples
        samples = collector.stop()

        # Should have collected some samples
        assert len(samples) >= 2

    def test_max_samples_limit_enforced(self):
        """Collector should not exceed max_samples."""
        collector = TimeSeriesCollector(interval_seconds=0.05, max_samples=3)

        collector.start()
        time.sleep(0.3)  # Would collect ~6 samples without limit
        samples = collector.stop()

        assert len(samples) <= 3

    def test_start_twice_raises_error(self):
        """Starting collector twice should raise RuntimeError."""
        collector = TimeSeriesCollector(interval_seconds=0.1)

        try:
            collector.start()
            with pytest.raises(RuntimeError, match="already started"):
                collector.start()
        finally:
            collector.stop()

    def test_stop_without_start_raises_error(self):
        """Stopping without starting should raise RuntimeError."""
        collector = TimeSeriesCollector()

        with pytest.raises(RuntimeError, match="not started"):
            collector.stop()

    def test_reuse_after_stop_raises_error(self):
        """Cannot restart a stopped collector."""
        collector = TimeSeriesCollector(interval_seconds=0.1)

        collector.start()
        collector.stop()

        with pytest.raises(RuntimeError, match="already stopped"):
            collector.start()

    def test_samples_contain_expected_fields(self):
        """Collected samples should have timestamp and hostname."""
        collector = TimeSeriesCollector(interval_seconds=0.1)

        collector.start()
        time.sleep(0.15)
        samples = collector.stop()

        if samples:
            sample = samples[0]
            assert 'timestamp' in sample
            assert 'hostname' in sample


class TestTimeSeriesSampleDataclass:
    """Tests for TimeSeriesSample dataclass."""

    def test_create_with_required_fields(self):
        """Can create sample with just timestamp and hostname."""
        from mlpstorage.rules.models import TimeSeriesSample

        sample = TimeSeriesSample(
            timestamp='2026-01-24T12:00:00Z',
            hostname='testhost'
        )

        assert sample.timestamp == '2026-01-24T12:00:00Z'
        assert sample.hostname == 'testhost'

    def test_to_dict_excludes_none(self):
        """to_dict should exclude None values."""
        from mlpstorage.rules.models import TimeSeriesSample

        sample = TimeSeriesSample(
            timestamp='2026-01-24T12:00:00Z',
            hostname='testhost',
            vmstat={'nr_free_pages': 12345}
        )

        d = sample.to_dict()
        assert 'timestamp' in d
        assert 'hostname' in d
        assert 'vmstat' in d
        assert 'diskstats' not in d  # None value excluded

    def test_from_dict_roundtrip(self):
        """Can roundtrip through to_dict/from_dict."""
        from mlpstorage.rules.models import TimeSeriesSample

        original = TimeSeriesSample(
            timestamp='2026-01-24T12:00:00Z',
            hostname='testhost',
            vmstat={'nr_free_pages': 12345},
            loadavg={'load_1min': 0.5, 'load_5min': 0.6, 'load_15min': 0.7}
        )

        d = original.to_dict()
        restored = TimeSeriesSample.from_dict(d)

        assert restored.timestamp == original.timestamp
        assert restored.hostname == original.hostname
        assert restored.vmstat == original.vmstat
        assert restored.loadavg == original.loadavg


class TestTimeSeriesDataDataclass:
    """Tests for TimeSeriesData dataclass."""

    def test_create_with_fields(self):
        """Can create TimeSeriesData with all fields."""
        from mlpstorage.rules.models import TimeSeriesSample, TimeSeriesData

        sample = TimeSeriesSample(
            timestamp='2026-01-24T12:00:00Z',
            hostname='host1'
        )

        data = TimeSeriesData(
            collection_interval_seconds=10.0,
            start_time='2026-01-24T12:00:00Z',
            end_time='2026-01-24T12:01:00Z',
            num_samples=6,
            samples_by_host={'host1': [sample]},
            collection_method='local',
            hosts_requested=['host1'],
            hosts_collected=['host1']
        )

        assert data.collection_interval_seconds == 10.0
        assert data.num_samples == 6

    def test_to_dict_serializes_samples(self):
        """to_dict should serialize nested samples."""
        from mlpstorage.rules.models import TimeSeriesSample, TimeSeriesData

        sample = TimeSeriesSample(
            timestamp='2026-01-24T12:00:00Z',
            hostname='host1',
            vmstat={'key': 123}
        )

        data = TimeSeriesData(
            collection_interval_seconds=10.0,
            start_time='2026-01-24T12:00:00Z',
            end_time='2026-01-24T12:01:00Z',
            num_samples=1,
            samples_by_host={'host1': [sample]},
            collection_method='local',
            hosts_requested=['host1'],
            hosts_collected=['host1']
        )

        d = data.to_dict()
        assert 'samples_by_host' in d
        assert 'host1' in d['samples_by_host']
        assert len(d['samples_by_host']['host1']) == 1
        assert d['samples_by_host']['host1'][0]['vmstat'] == {'key': 123}

    def test_from_dict_roundtrip(self):
        """Can roundtrip TimeSeriesData through to_dict/from_dict."""
        from mlpstorage.rules.models import TimeSeriesSample, TimeSeriesData

        sample = TimeSeriesSample(
            timestamp='2026-01-24T12:00:00Z',
            hostname='host1'
        )

        original = TimeSeriesData(
            collection_interval_seconds=10.0,
            start_time='2026-01-24T12:00:00Z',
            end_time='2026-01-24T12:01:00Z',
            num_samples=1,
            samples_by_host={'host1': [sample]},
            collection_method='ssh',
            hosts_requested=['host1', 'host2'],
            hosts_collected=['host1']
        )

        d = original.to_dict()
        restored = TimeSeriesData.from_dict(d)

        assert restored.collection_interval_seconds == original.collection_interval_seconds
        assert restored.collection_method == original.collection_method
        assert restored.hosts_requested == original.hosts_requested
        assert len(restored.samples_by_host['host1']) == 1
```

Add required import at top of test file if not present:
```python
import time
import pytest
from mlpstorage.cluster_collector import collect_timeseries_sample, TimeSeriesCollector
```
  </action>
  <verify>Run `pytest tests/unit/test_cluster_collector.py -v -k "timeseries or TimeSeriesSample or TimeSeriesData" --tb=short` - all tests should pass</verify>
  <done>All time-series collection unit tests pass</done>
</task>

</tasks>

<verification>
1. Import check: `python -c "from mlpstorage.rules.models import TimeSeriesSample, TimeSeriesData; from mlpstorage.cluster_collector import collect_timeseries_sample, TimeSeriesCollector; print('All imports OK')"`
2. Functional test: `python -c "from mlpstorage.cluster_collector import TimeSeriesCollector; import time; c = TimeSeriesCollector(interval_seconds=0.5); c.start(); time.sleep(1.5); s = c.stop(); print(f'Collected {len(s)} samples'); assert len(s) >= 2"`
3. Unit tests: `pytest tests/unit/test_cluster_collector.py -v -k "timeseries or TimeSeriesSample or TimeSeriesData" --tb=short`
</verification>

<success_criteria>
1. TimeSeriesSample and TimeSeriesData dataclasses exist in models.py with to_dict/from_dict methods
2. collect_timeseries_sample() returns dict with diskstats, vmstat, loadavg, meminfo, netdev
3. TimeSeriesCollector.start() starts background collection thread
4. TimeSeriesCollector.stop() stops collection and returns list of samples
5. Collector respects max_samples limit
6. All unit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/07-time-series-host-data-collection/07-01-SUMMARY.md`
</output>
