---
phase: 08-new-training-models
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - mlpstorage/config.py
  - configs/dlio/workload/dlrm_h100.yaml
  - configs/dlio/workload/dlrm_a100.yaml
  - configs/dlio/workload/dlrm_datagen.yaml
  - configs/dlio/workload/retinanet_h100.yaml
  - configs/dlio/workload/retinanet_a100.yaml
  - configs/dlio/workload/retinanet_datagen.yaml
  - configs/dlio/workload/flux_h100.yaml
  - configs/dlio/workload/flux_a100.yaml
  - configs/dlio/workload/flux_datagen.yaml
autonomous: true

must_haves:
  truths:
    - "User can select dlrm, retinanet, or flux as --model argument"
    - "User can run datagen for all three new models"
    - "User can run training benchmark with new models (CLI accepts and passes to DLIO)"
  artifacts:
    - path: "mlpstorage/config.py"
      provides: "Model constants DLRM, RETINANET, FLUX in MODELS list"
      contains: "MODELS = [COSMOFLOW, RESNET, UNET, DLRM, RETINANET, FLUX]"
    - path: "configs/dlio/workload/dlrm_h100.yaml"
      provides: "DLRM H100 training configuration"
    - path: "configs/dlio/workload/dlrm_a100.yaml"
      provides: "DLRM A100 training configuration"
    - path: "configs/dlio/workload/dlrm_datagen.yaml"
      provides: "DLRM data generation configuration"
    - path: "configs/dlio/workload/retinanet_h100.yaml"
      provides: "RetinaNet H100 training configuration"
    - path: "configs/dlio/workload/retinanet_a100.yaml"
      provides: "RetinaNet A100 training configuration"
    - path: "configs/dlio/workload/retinanet_datagen.yaml"
      provides: "RetinaNet data generation configuration"
    - path: "configs/dlio/workload/flux_h100.yaml"
      provides: "Flux H100 training configuration"
    - path: "configs/dlio/workload/flux_a100.yaml"
      provides: "Flux A100 training configuration"
    - path: "configs/dlio/workload/flux_datagen.yaml"
      provides: "Flux data generation configuration"
  key_links:
    - from: "mlpstorage/config.py"
      to: "mlpstorage/cli/training_args.py"
      via: "MODELS import for CLI choices"
      pattern: "from mlpstorage.config import MODELS"
    - from: "configs/dlio/workload/*.yaml"
      to: "DLIO benchmark engine"
      via: "Hydra configuration loading"
---

<objective>
Add DLRM, RetinaNet, and Flux model configurations to the MLPerf Storage benchmark suite.

Purpose: Enable users to run training benchmarks for three new MLPerf Training models (recommendation, object detection, text-to-image) with appropriate I/O emulation characteristics.

Output: Model constants in config.py and 9 YAML configuration files (3 models x 3 configs each: h100, a100, datagen).
</objective>

<execution_context>
@./.claude/agents/gsd-planner.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-new-training-models/08-RESEARCH.md

# Existing patterns to follow
@mlpstorage/config.py
@configs/dlio/workload/unet3d_h100.yaml
@configs/dlio/workload/unet3d_datagen.yaml
@configs/dlio/workload/resnet50_h100.yaml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add model constants to config.py</name>
  <files>mlpstorage/config.py</files>
  <action>
Add three new model constants after the existing UNET constant (around line 50):

```python
COSMOFLOW = "cosmoflow"
RESNET = "resnet50"
UNET = "unet3d"
DLRM = "dlrm"
RETINANET = "retinanet"
FLUX = "flux"
MODELS = [COSMOFLOW, RESNET, UNET, DLRM, RETINANET, FLUX]
```

This follows the exact pattern of existing constants. The MODELS list is used by CLI argument parsers for --model choices.
  </action>
  <verify>
Run: `python -c "from mlpstorage.config import DLRM, RETINANET, FLUX, MODELS; print(MODELS)"`
Expected output includes all 6 models: cosmoflow, resnet50, unet3d, dlrm, retinanet, flux
  </verify>
  <done>DLRM, RETINANET, FLUX constants defined and included in MODELS list</done>
</task>

<task type="auto">
  <name>Task 2: Create DLRM YAML configurations</name>
  <files>
    configs/dlio/workload/dlrm_h100.yaml
    configs/dlio/workload/dlrm_a100.yaml
    configs/dlio/workload/dlrm_datagen.yaml
  </files>
  <action>
Create three YAML files for DLRM (recommendation model). Follow the pattern from unet3d_h100.yaml and resnet50_h100.yaml.

NOTE: Existing DLIO configs use `model.type: cnn` for image models (unet3d, resnet50) or omit the field entirely (cosmoflow). For new models, omit model.type if unsure of DLIO's supported types, as DLIO will use default behavior. The model.name field is what DLIO uses for identification.

**dlrm_h100.yaml:**
- model.name: dlrm
- (omit model.type - DLIO uses name for model identification)
- framework: pytorch
- dataset.format: npz (parquet preferred but requires Phase 9)
- dataset.num_files_train: 65536 (high file count for recommendation data)
- dataset.num_samples_per_file: 1
- dataset.record_length_bytes: 512 (per-sample multi-hot encoding size)
- dataset.data_folder: data/dlrm/
- reader.batch_size: 8192 (DLRMv2 uses large batches)
- reader.read_threads: 8
- train.epochs: 1 (DLRM reaches target in < 1 epoch)
- train.computation_time: 0.005 (fast per-batch)
- metric.au: 0.70 (lower AU due to high I/O bandwidth)
- workflow: generate_data=False, train=True, checkpoint=False

**dlrm_a100.yaml:**
- Same as H100 but adjust computation_time: 0.007 (A100 slightly slower)

**dlrm_datagen.yaml:**
- workflow: generate_data=True, train=False, checkpoint=False
- Include dataset parameters but no train/metric sections
  </action>
  <verify>
Run: `ls configs/dlio/workload/dlrm_*.yaml` - should show 3 files
Run: `grep -l "name: dlrm" configs/dlio/workload/*.yaml` - should match 3 files
  </verify>
  <done>DLRM has h100, a100, and datagen YAML configs</done>
</task>

<task type="auto">
  <name>Task 3: Create RetinaNet YAML configurations</name>
  <files>
    configs/dlio/workload/retinanet_h100.yaml
    configs/dlio/workload/retinanet_a100.yaml
    configs/dlio/workload/retinanet_datagen.yaml
  </files>
  <action>
**RetinaNet (object detection, CNN-based):**

**retinanet_h100.yaml:**
- model.name: retinanet
- model.type: cnn (RetinaNet is a CNN-based object detector, same type as unet3d/resnet50)
- framework: pytorch
- dataset.format: jpeg
- dataset.num_files_train: 1743042 (OpenImages training set)
- dataset.num_samples_per_file: 1
- dataset.record_length_bytes: 153600 (~150KB avg JPEG at 800x800)
- dataset.record_length_bytes_stdev: 51200
- dataset.data_folder: data/retinanet/
- reader.batch_size: 16
- reader.read_threads: 8
- train.epochs: 5
- train.computation_time: 0.180 (object detection is compute intensive)
- metric.au: 0.85
- workflow: generate_data=False, train=True, checkpoint=False

**retinanet_a100.yaml:**
- Same as H100, adjust computation_time: 0.210

**retinanet_datagen.yaml:**
- workflow: generate_data=True, train=False, checkpoint=False
  </action>
  <verify>
Run: `ls configs/dlio/workload/retinanet_*.yaml` - should show 3 files
Run: `grep "model:" configs/dlio/workload/retinanet_h100.yaml` - should show model section
  </verify>
  <done>RetinaNet has h100, a100, and datagen YAML configs</done>
</task>

<task type="auto">
  <name>Task 4: Create Flux YAML configurations</name>
  <files>
    configs/dlio/workload/flux_h100.yaml
    configs/dlio/workload/flux_a100.yaml
    configs/dlio/workload/flux_datagen.yaml
  </files>
  <action>
**Flux (text-to-image diffusion, transformer-based):**

**flux_h100.yaml:**
- model.name: flux
- (omit model.type - Flux is a diffusion/transformer model, not a standard DLIO type)
- framework: pytorch
- dataset.format: jpeg (CC12M image+caption pairs, DLIO handles image-only)
- dataset.num_files_train: 1099776 (CC12M subset for MLPerf)
- dataset.num_samples_per_file: 1
- dataset.record_length_bytes: 307200 (1024x1024 JPEG avg)
- dataset.record_length_bytes_stdev: 102400
- dataset.data_folder: data/flux/
- reader.batch_size: 8 (memory constrained for 11.9B model)
- reader.read_threads: 8
- train.epochs: 5
- train.computation_time: 0.850 (large transformer model)
- metric.au: 0.80
- workflow: generate_data=False, train=True, checkpoint=False

**flux_a100.yaml:**
- Same as H100, adjust computation_time: 1.100

**flux_datagen.yaml:**
- workflow: generate_data=True, train=False, checkpoint=False
  </action>
  <verify>
Run: `ls configs/dlio/workload/flux_*.yaml` - should show 3 files
Run: `grep "model:" configs/dlio/workload/flux_h100.yaml` - should show model section
  </verify>
  <done>Flux has h100, a100, and datagen YAML configs</done>
</task>

</tasks>

<verification>
1. All 9 new YAML files exist in configs/dlio/workload/
2. config.py exports DLRM, RETINANET, FLUX constants
3. MODELS list contains all 6 models
4. CLI accepts new models: `mlpstorage training run --help` shows dlrm, retinanet, flux in choices
5. Existing tests still pass: `pytest tests/unit -v -k "not test_rules_calculations"`
</verification>

<success_criteria>
- `python -c "from mlpstorage.config import DLRM, RETINANET, FLUX; print('OK')"` prints OK
- `ls configs/dlio/workload/*.yaml | wc -l` shows 22 files (was 13, added 9)
- `mlpstorage training run --help` shows dlrm, retinanet, flux as valid --model choices
- All YAML files have valid structure (model, framework, workflow, dataset, reader sections)
</success_criteria>

<output>
After completion, create `.planning/phases/08-new-training-models/08-01-SUMMARY.md`
</output>
