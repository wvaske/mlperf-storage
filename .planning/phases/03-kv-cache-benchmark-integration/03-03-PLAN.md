---
phase: 03-kv-cache-benchmark-integration
plan: 03
type: execute
wave: 3
depends_on: ["03-01", "03-02"]
files_modified:
  - mlpstorage/benchmarks/kvcache.py
  - tests/unit/test_benchmarks_kvcache.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "KV cache benchmark metadata includes all required fields for history list"
    - "User can see KV cache benchmark runs in mlpstorage history list output"
    - "Metadata JSON is consistent with training/checkpointing benchmarks"
    - "Cluster information appears in metadata for distributed runs"
  artifacts:
    - path: "mlpstorage/benchmarks/kvcache.py"
      provides: "Complete metadata for history integration"
      contains: "num_processes"
  key_links:
    - from: "mlpstorage/benchmarks/kvcache.py.metadata"
      to: "mlpstorage/history.py"
      via: "metadata JSON structure"
      pattern: "benchmark_type.*model.*run_datetime.*result_dir"
---

<objective>
Verify and enhance KV cache benchmark metadata for history integration.

Purpose: Ensure KV cache benchmark runs appear correctly in `mlpstorage history list` output and metadata is consistent with other benchmark types.

Output: KVCacheBenchmark with complete metadata compatible with history module and other benchmark types.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-kv-cache-benchmark-integration/03-RESEARCH.md
@.planning/phases/03-kv-cache-benchmark-integration/03-01-SUMMARY.md
@.planning/phases/03-kv-cache-benchmark-integration/03-02-SUMMARY.md

# Reference for metadata structure:
@mlpstorage/benchmarks/base.py
@mlpstorage/benchmarks/kvcache.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Verify and enhance KV cache metadata structure</name>
  <files>mlpstorage/benchmarks/kvcache.py</files>
  <action>
  Review and update the `metadata` property in KVCacheBenchmark to ensure all required fields are present:

  1. Verify the existing metadata property includes:
     - benchmark_type (from base class)
     - model (as 'kvcache_model' - should also include as 'model' for consistency)
     - command (from base class)
     - run_datetime (from base class)
     - result_dir (from base class)
     - num_processes (for distributed runs)

  2. Update the `metadata` property to include `num_processes`:
     ```python
     @property
     def metadata(self) -> Dict[str, Any]:
         """Generate metadata for the KV cache benchmark run."""
         base_metadata = super().metadata

         # Add KV cache specific metadata
         base_metadata.update({
             'kvcache_model': self.model,
             'model': self.model,  # Add for consistency with other benchmarks
             'num_users': self.num_users,
             'duration': self.duration,
             'gpu_mem_gb': self.gpu_mem_gb,
             'cpu_mem_gb': self.cpu_mem_gb,
             'cache_dir': self.cache_dir,
             'generation_mode': self.generation_mode,
             'performance_profile': self.performance_profile,
             'num_processes': self.num_processes,  # Add for distributed runs
         })

         # Add execution info
         exec_type = getattr(self.args, 'exec_type', None)
         if exec_type:
             base_metadata['exec_type'] = exec_type.value if hasattr(exec_type, 'value') else str(exec_type)

         hosts = getattr(self.args, 'hosts', None)
         if hosts:
             base_metadata['hosts'] = hosts

         # Add metrics if available
         if hasattr(self, 'metrics'):
             base_metadata['kvcache_metrics'] = self.metrics

         return base_metadata
     ```

  3. Ensure cluster_information is included via base class when collected.
  </action>
  <verify>
  Run Python to verify metadata structure:
  ```python
  from argparse import Namespace
  from mlpstorage.benchmarks.kvcache import KVCacheBenchmark
  from mlpstorage.config import EXEC_TYPE
  from unittest.mock import MagicMock, patch
  import json

  logger = MagicMock()
  logger.status = MagicMock()
  logger.info = MagicMock()
  logger.debug = MagicMock()
  logger.warning = MagicMock()
  logger.verboser = MagicMock()

  args = Namespace(
      command='run',
      model='llama3.1-8b',
      num_users=100,
      duration=60,
      gpu_mem_gb=16.0,
      cpu_mem_gb=32.0,
      cache_dir='/tmp/cache',
      generation_mode='realistic',
      performance_profile='latency',
      exec_type=EXEC_TYPE.MPI,
      hosts=['host1', 'host2'],
      num_processes=2,
      mpi_bin='mpirun',
      oversubscribe=False,
      allow_run_as_root=False,
      mpi_params=None,
      kvcache_bin_path=None,
      disable_multi_turn=False,
      disable_prefix_caching=False,
      enable_rag=False,
      enable_autoscaling=False,
      seed=None,
      results_dir='/tmp/results',
      closed=False,
      what_if=True,
      debug=False,
      verbose=False,
      stream_log_level='INFO',
  )

  with patch.object(KVCacheBenchmark, '_collect_cluster_information', return_value=None):
      bm = KVCacheBenchmark(args, logger=logger)
      meta = bm.metadata

  # Check required fields
  required = ['benchmark_type', 'model', 'command', 'run_datetime', 'result_dir', 'num_processes']
  for field in required:
      assert field in meta, f"Missing field: {field}"
      print(f"  {field}: {meta[field]}")

  # Check kvcache-specific fields
  assert 'kvcache_model' in meta
  assert 'hosts' in meta
  assert 'exec_type' in meta
  print("OK: All required metadata fields present")
  ```
  </verify>
  <done>
  - metadata property includes all required fields for history integration
  - 'model' field is present (in addition to 'kvcache_model') for consistency
  - num_processes is included for distributed runs
  - hosts and exec_type are included when applicable
  </done>
</task>

<task type="auto">
  <name>Task 2: Add integration test for history list compatibility</name>
  <files>tests/unit/test_benchmarks_kvcache.py</files>
  <action>
  Add tests to verify metadata compatibility with history module:

  ```python
  class TestKVCacheMetadata:
      """Test metadata structure for history integration."""

      def test_metadata_has_required_fields(self, base_args, mock_logger):
          """Verify metadata includes fields required by history module."""
          base_args.exec_type = None
          base_args.hosts = None
          base_args.num_processes = None
          base_args.mpi_bin = 'mpirun'
          base_args.oversubscribe = False
          base_args.allow_run_as_root = False
          base_args.mpi_params = None

          with patch.object(KVCacheBenchmark, '_collect_cluster_information', return_value=None):
              bm = KVCacheBenchmark(base_args, logger=mock_logger)
              meta = bm.metadata

          # Required by history module
          assert 'benchmark_type' in meta
          assert 'model' in meta
          assert 'command' in meta
          assert 'run_datetime' in meta
          assert 'result_dir' in meta

      def test_metadata_includes_kvcache_specific_fields(self, base_args, mock_logger):
          """Verify KV cache specific metadata fields."""
          base_args.exec_type = None
          base_args.hosts = None
          base_args.num_processes = None
          base_args.mpi_bin = 'mpirun'
          base_args.oversubscribe = False
          base_args.allow_run_as_root = False
          base_args.mpi_params = None

          with patch.object(KVCacheBenchmark, '_collect_cluster_information', return_value=None):
              bm = KVCacheBenchmark(base_args, logger=mock_logger)
              meta = bm.metadata

          assert 'kvcache_model' in meta
          assert 'num_users' in meta
          assert 'duration' in meta
          assert 'gpu_mem_gb' in meta
          assert 'cpu_mem_gb' in meta
          assert 'generation_mode' in meta
          assert 'performance_profile' in meta

      def test_metadata_includes_distributed_info(self, base_args, mock_logger):
          """Verify metadata includes distributed execution info."""
          base_args.exec_type = EXEC_TYPE.MPI
          base_args.hosts = ['host1', 'host2']
          base_args.num_processes = 4
          base_args.mpi_bin = 'mpirun'
          base_args.oversubscribe = False
          base_args.allow_run_as_root = False
          base_args.mpi_params = None

          with patch.object(KVCacheBenchmark, '_collect_cluster_information', return_value=None):
              bm = KVCacheBenchmark(base_args, logger=mock_logger)
              meta = bm.metadata

          assert 'num_processes' in meta
          assert meta['num_processes'] == 4
          assert 'hosts' in meta
          assert meta['hosts'] == ['host1', 'host2']
          assert 'exec_type' in meta

      def test_metadata_model_consistency(self, base_args, mock_logger):
          """Verify 'model' field matches 'kvcache_model' for history compatibility."""
          base_args.model = 'llama3.1-70b-instruct'
          base_args.exec_type = None
          base_args.hosts = None
          base_args.num_processes = None
          base_args.mpi_bin = 'mpirun'
          base_args.oversubscribe = False
          base_args.allow_run_as_root = False
          base_args.mpi_params = None

          with patch.object(KVCacheBenchmark, '_collect_cluster_information', return_value=None):
              bm = KVCacheBenchmark(base_args, logger=mock_logger)
              meta = bm.metadata

          assert meta['model'] == 'llama3.1-70b-instruct'
          assert meta['kvcache_model'] == 'llama3.1-70b-instruct'
  ```
  </action>
  <verify>
  Run: `pytest tests/unit/test_benchmarks_kvcache.py::TestKVCacheMetadata -v`
  All tests should pass.
  </verify>
  <done>
  - 4 new tests verify metadata structure
  - Tests confirm required fields for history module
  - Tests confirm KV cache specific fields
  - Tests confirm distributed execution info in metadata
  - Tests confirm model field consistency
  </done>
</task>

<task type="auto">
  <name>Task 3: End-to-end verification with what-if mode</name>
  <files>N/A (verification only)</files>
  <action>
  Run end-to-end verification using --what-if mode to confirm the complete integration:

  1. Verify local execution:
     ```bash
     mlpstorage kvcache run --model llama3.1-8b --num-users 50 --duration 30 \
       --results-dir /tmp/kv-test --what-if
     ```

  2. Verify distributed execution (what-if mode):
     ```bash
     mlpstorage kvcache run --model llama3.1-8b --num-users 50 --duration 30 \
       --hosts host1 host2 --exec-type mpi --num-processes 2 \
       --results-dir /tmp/kv-test --what-if
     ```

  3. Check help output shows all arguments:
     ```bash
     mlpstorage kvcache run --help
     ```

  4. Run all kvcache tests:
     ```bash
     pytest tests/unit/test_benchmarks_kvcache.py tests/unit/test_cli_kvcache.py -v
     ```
  </action>
  <verify>
  All commands should execute without error:
  1. Local execution --what-if shows command without MPI prefix
  2. Distributed --what-if shows command WITH mpirun prefix and host list
  3. Help shows --hosts, --exec-type, --num-processes, MPI arguments
  4. All tests pass
  </verify>
  <done>
  - Local kvcache run works with --what-if
  - Distributed kvcache run shows MPI-wrapped command in --what-if
  - Help output shows all new distributed execution arguments
  - All unit tests pass
  </done>
</task>

</tasks>

<verification>
1. KVCacheBenchmark.metadata includes all required fields:
   - benchmark_type, model, command, run_datetime, result_dir
   - num_processes, hosts, exec_type for distributed runs
   - kvcache_model, num_users, duration, gpu_mem_gb, cpu_mem_gb

2. `mlpstorage kvcache run --what-if` works for both local and distributed execution

3. All unit tests pass:
   ```bash
   pytest tests/unit/test_benchmarks_kvcache.py tests/unit/test_cli_kvcache.py -v
   ```

4. Help shows all arguments:
   ```bash
   mlpstorage kvcache run --help
   ```
</verification>

<success_criteria>
- KV cache benchmark metadata is complete and consistent with other benchmarks
- Distributed execution info (hosts, num_processes, exec_type) appears in metadata
- --what-if mode works for both local and distributed execution
- All unit tests pass
- Phase 3 success criteria met:
  1. User can run `mlpstorage kvcache run` with standard result directory structure
  2. User can run KV cache benchmark across multiple hosts using MPI with --hosts argument
  3. KV cache benchmark generates metadata JSON consistent with training/checkpointing
  4. (History list verification would require actual run - verified via metadata structure)
</success_criteria>

<output>
After completion, create `.planning/phases/03-kv-cache-benchmark-integration/03-03-SUMMARY.md`
</output>
