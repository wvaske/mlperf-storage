---
phase: 04-vectordb-benchmark-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - mlpstorage/cli/vectordb_args.py
  - mlpstorage/cli/common_args.py
  - mlpstorage/benchmarks/vectordbbench.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "User can run `mlpstorage vectordb run` (not run-search)"
    - "User can run `mlpstorage vectordb datagen`"
    - "CLI help shows 'run' subcommand, not 'run-search'"
  artifacts:
    - path: "mlpstorage/cli/vectordb_args.py"
      provides: "Renamed run subcommand"
      contains: "'run'"
    - path: "mlpstorage/benchmarks/vectordbbench.py"
      provides: "Updated command_method_map"
      contains: '"run": self.execute_run'
  key_links:
    - from: "mlpstorage/cli/vectordb_args.py"
      to: "mlpstorage/benchmarks/vectordbbench.py"
      via: "command_method_map key matches CLI subcommand name"
      pattern: '"run".*execute_run'
---

<objective>
Rename VectorDB CLI subcommand from 'run-search' to 'run' for consistency with other benchmarks (training, checkpointing, kvcache all use 'run').

Purpose: Consistent CLI experience across all benchmark types - users expect `mlpstorage {benchmark} run`.
Output: Updated CLI arguments and command handler mapping.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-vectordb-benchmark-integration/04-RESEARCH.md

# Reference implementations
@mlpstorage/cli/kvcache_args.py
@mlpstorage/benchmarks/kvcache.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rename run-search to run in CLI</name>
  <files>mlpstorage/cli/vectordb_args.py, mlpstorage/cli/common_args.py</files>
  <action>
1. In vectordb_args.py:
   - Change `vectordb_subparsers.add_parser('run-search', ...)` to `vectordb_subparsers.add_parser('run', ...)`
   - Rename variable from `run_search` to `run_benchmark` for clarity
   - Update the loop that adds common arguments to use `run_benchmark` instead of `run_search`
   - Update help reference from `HELP_MESSAGES['vdb_run_search']` to `HELP_MESSAGES['vdb_run']`

2. In common_args.py HELP_MESSAGES dict:
   - Rename key `'vdb_run_search'` to `'vdb_run'`
   - Keep message content the same: "Run the VectorDB Search benchmark with the specified parameters."
  </action>
  <verify>
  ```bash
  python -c "from mlpstorage.cli.vectordb_args import add_vectordb_arguments; import argparse; p = argparse.ArgumentParser(); add_vectordb_arguments(p); args = p.parse_args(['run']); print(args.command)"
  ```
  Output should be: `run`
  </verify>
  <done>CLI accepts `mlpstorage vectordb run` and `mlpstorage vectordb datagen` commands</done>
</task>

<task type="auto">
  <name>Task 2: Update command_method_map in VectorDBBenchmark</name>
  <files>mlpstorage/benchmarks/vectordbbench.py</files>
  <action>
In VectorDBBenchmark.__init__, update the command_method_map:
- Change `"run-search": self.execute_run` to `"run": self.execute_run`

The map should become:
```python
self.command_method_map = {
    "datagen": self.execute_datagen,
    "run": self.execute_run,  # Changed from "run-search"
}
```
  </action>
  <verify>
  ```bash
  python -c "
from argparse import Namespace
from unittest.mock import patch
import os
import tempfile

args = Namespace(
    debug=False, verbose=False, what_if=False, stream_log_level='INFO',
    results_dir=tempfile.gettempdir(),
    command='run', config='default', host='127.0.0.1', port=19530,
    num_query_processes=1, batch_size=1, runtime=60, queries=None,
    report_count=100, collection=None, category=None,
)

with patch('mlpstorage.benchmarks.vectordbbench.Benchmark.__init__', return_value=None):
    from mlpstorage.benchmarks.vectordbbench import VectorDBBenchmark
    bm = VectorDBBenchmark.__new__(VectorDBBenchmark)
    bm.args = args
    bm.command = 'run'
    bm.command_method_map = {'datagen': None, 'run': None}
    assert 'run' in bm.command_method_map
    assert 'run-search' not in bm.command_method_map
    print('command_method_map correctly updated')
"
  ```
  </verify>
  <done>VectorDBBenchmark routes 'run' command to execute_run method</done>
</task>

</tasks>

<verification>
1. CLI help shows correct subcommands:
   ```bash
   python -m mlpstorage vectordb --help
   ```
   Should show `{datagen,run}` not `{datagen,run-search}`

2. Both commands parse correctly:
   ```bash
   python -c "from mlpstorage.cli.vectordb_args import add_vectordb_arguments; import argparse; p = argparse.ArgumentParser(); add_vectordb_arguments(p); p.parse_args(['run'])"
   python -c "from mlpstorage.cli.vectordb_args import add_vectordb_arguments; import argparse; p = argparse.ArgumentParser(); add_vectordb_arguments(p); p.parse_args(['datagen'])"
   ```

3. All existing tests still pass:
   ```bash
   pytest tests/unit -v -k "not integration" --tb=short
   ```
</verification>

<success_criteria>
- `mlpstorage vectordb run --help` works and shows run-specific arguments
- `mlpstorage vectordb datagen --help` works and shows datagen-specific arguments
- CLI help displays `{datagen,run}` as subcommand choices
- VectorDBBenchmark.command_method_map contains 'run' key (not 'run-search')
- All existing unit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/04-vectordb-benchmark-integration/04-01-SUMMARY.md`
</output>
