---
phase: 05-benchmark-validation-pipeline-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - mlpstorage/rules/run_checkers/vectordb.py
  - mlpstorage/rules/run_checkers/__init__.py
  - mlpstorage/rules/__init__.py
autonomous: true

must_haves:
  truths:
    - "VectorDBRunRulesChecker validates vector_database benchmark runs"
    - "VectorDBRunRulesChecker is importable from mlpstorage.rules"
    - "VectorDBRunRulesChecker auto-discovers check_* methods"
    - "VectorDB runs return OPEN due to preview status"
  artifacts:
    - path: "mlpstorage/rules/run_checkers/vectordb.py"
      provides: "VectorDBRunRulesChecker class"
      exports: ["VectorDBRunRulesChecker"]
      min_lines: 50
    - path: "mlpstorage/rules/run_checkers/__init__.py"
      provides: "Exports VectorDBRunRulesChecker"
      contains: "VectorDBRunRulesChecker"
    - path: "mlpstorage/rules/__init__.py"
      provides: "Top-level export of VectorDBRunRulesChecker"
      contains: "VectorDBRunRulesChecker"
  key_links:
    - from: "mlpstorage/rules/run_checkers/vectordb.py"
      to: "mlpstorage/rules/run_checkers/base.py"
      via: "class inheritance"
      pattern: "class VectorDBRunRulesChecker\\(RunRulesChecker\\)"
---

<objective>
Create VectorDBRunRulesChecker for validating vector database benchmark runs.

Purpose: Enable validation of VectorDB benchmark results using the established rules framework. VectorDB is in preview status, so all runs should return OPEN category.

Output: A new VectorDBRunRulesChecker class following the established KVCacheRunRulesChecker pattern, exported from the rules module.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-benchmark-validation-pipeline-integration/05-RESEARCH.md

# Reference implementation
@mlpstorage/rules/run_checkers/kvcache.py
@mlpstorage/rules/run_checkers/base.py
@mlpstorage/rules/run_checkers/__init__.py
@mlpstorage/rules/__init__.py
@mlpstorage/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create VectorDBRunRulesChecker</name>
  <files>mlpstorage/rules/run_checkers/vectordb.py</files>
  <action>
Create `VectorDBRunRulesChecker` following the `KVCacheRunRulesChecker` pattern:

1. Import required types:
   - `Optional` from typing
   - `BENCHMARK_TYPES`, `PARAM_VALIDATION` from mlpstorage.config
   - `Issue` from mlpstorage.rules.issues
   - `RunRulesChecker` from mlpstorage.rules.run_checkers.base

2. Create class `VectorDBRunRulesChecker(RunRulesChecker)` with docstring noting preview status.

3. Define class constants:
   - `MIN_RUNTIME_SECONDS = 30` (matches VECTORDB_DEFAULT_RUNTIME constraint)

4. Implement check methods:
   - `check_benchmark_type()`: Return INVALID if benchmark_type != BENCHMARK_TYPES.vector_database
   - `check_runtime()`: Get 'runtime' from parameters (default 60). Return INVALID if < MIN_RUNTIME_SECONDS
   - `check_preview_status()`: Always return OPEN Issue with message "VectorDB benchmark is in preview status - not accepted for closed submissions"

Note: Follow the established pattern where check methods return Optional[Issue] or None.
  </action>
  <verify>
Run: `python -c "from mlpstorage.rules.run_checkers.vectordb import VectorDBRunRulesChecker; print('Import OK')"`
  </verify>
  <done>VectorDBRunRulesChecker class exists with check_benchmark_type, check_runtime, and check_preview_status methods</done>
</task>

<task type="auto">
  <name>Task 2: Export VectorDBRunRulesChecker from run_checkers package</name>
  <files>mlpstorage/rules/run_checkers/__init__.py</files>
  <action>
Update the run_checkers __init__.py to export VectorDBRunRulesChecker:

1. Add import:
   `from mlpstorage.rules.run_checkers.vectordb import VectorDBRunRulesChecker`

2. Add to __all__ list:
   `'VectorDBRunRulesChecker'`

Follow the existing pattern for KVCacheRunRulesChecker.
  </action>
  <verify>
Run: `python -c "from mlpstorage.rules.run_checkers import VectorDBRunRulesChecker; print('OK')"`
  </verify>
  <done>VectorDBRunRulesChecker is importable from mlpstorage.rules.run_checkers</done>
</task>

<task type="auto">
  <name>Task 3: Export VectorDBRunRulesChecker from rules package</name>
  <files>mlpstorage/rules/__init__.py</files>
  <action>
Update the rules __init__.py to export VectorDBRunRulesChecker:

1. Add to the run_checkers import block:
   Add `VectorDBRunRulesChecker` to the existing import from mlpstorage.rules.run_checkers

2. Add to __all__ list in the "Run Checkers" section:
   `'VectorDBRunRulesChecker'`

Follow the existing pattern for KVCacheRunRulesChecker.
  </action>
  <verify>
Run: `python -c "from mlpstorage.rules import VectorDBRunRulesChecker; print('OK')"`
  </verify>
  <done>VectorDBRunRulesChecker is importable from mlpstorage.rules (top-level)</done>
</task>

</tasks>

<verification>
1. Import chain works:
   ```bash
   python -c "from mlpstorage.rules import VectorDBRunRulesChecker; print('Import OK')"
   ```

2. Checker has required methods:
   ```bash
   python -c "
from mlpstorage.rules import VectorDBRunRulesChecker
checker_methods = [m for m in dir(VectorDBRunRulesChecker) if m.startswith('check_')]
assert 'check_benchmark_type' in checker_methods
assert 'check_runtime' in checker_methods
assert 'check_preview_status' in checker_methods
print('Methods OK:', checker_methods)
"
   ```

3. Run existing tests to ensure no regressions:
   ```bash
   pytest tests/unit/test_rules_checkers.py -v
   ```
</verification>

<success_criteria>
- VectorDBRunRulesChecker class exists at mlpstorage/rules/run_checkers/vectordb.py
- Class inherits from RunRulesChecker
- Class has check_benchmark_type, check_runtime, and check_preview_status methods
- VectorDBRunRulesChecker is importable from mlpstorage.rules
- Existing rules tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/05-benchmark-validation-pipeline-integration/05-01-SUMMARY.md`
</output>
